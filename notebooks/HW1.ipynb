{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Homework 1\n",
    "\n",
    "Dataset: sklearn.datasets.load_breast_cancer() (569 samples, 30 numeric features, benign = 1 / malignant = 0)\n",
    "\n",
    "\n",
    "Goal: Use accuracy to compare six classifiers: Linear Regression (thresholded at 0.5), Logistic Regression, K-Nearest Neighbors (KNN), Gaussian Naive Bayes, Linear Discriminant Analysis (LDA), and Quadratic Discriminant Analysis (QDA).\n",
    "\n"
   ],
   "id": "735bdef6ef586a80"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:33.442946Z",
     "start_time": "2025-09-24T00:55:33.431923Z"
    }
   },
   "source": [
    "# Import statements and such\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 1",
   "id": "4ee192b377b9cc12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:33.488295Z",
     "start_time": "2025-09-24T00:55:33.457903Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # 1. Load Data\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Data Shape\n",
    "print(\"X Shape\", X.shape)\n",
    "print(\"Y Shape\", y.shape)\n",
    "\n",
    "# Display the Feature names\n",
    "print(\"Feature Names:\", list(X.columns))\n",
    "\n",
    "# Display the Class Counts\n",
    "print(\"Class Counts: \\n \", y.value_counts())\n",
    "\n",
    "# Print summary stats for 5 random features\n",
    "# I choose mean smoothness, area error, worst concave point, worst texture, and mean area\n",
    "print(X[['mean smoothness','area error','worst concave points','worst texture', 'mean area']].describe())\n",
    "\n",
    "# Split the data into 70% and 30% test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify = y, random_state=42)# when i asked chatgbt to check my code it told me to add startify = y because without it the train/tests sets may be imbalanced"
   ],
   "id": "e6b837fd084de95c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape (569, 30)\n",
      "Y Shape (569,)\n",
      "Feature Names: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "Class Counts: \n",
      "  target\n",
      "1    357\n",
      "0    212\n",
      "Name: count, dtype: int64\n",
      "       mean smoothness  area error  worst concave points  worst texture  \\\n",
      "count       569.000000  569.000000            569.000000     569.000000   \n",
      "mean          0.096360   40.337079              0.114606      25.677223   \n",
      "std           0.014064   45.491006              0.065732       6.146258   \n",
      "min           0.052630    6.802000              0.000000      12.020000   \n",
      "25%           0.086370   17.850000              0.064930      21.080000   \n",
      "50%           0.095870   24.530000              0.099930      25.410000   \n",
      "75%           0.105300   45.190000              0.161400      29.720000   \n",
      "max           0.163400  542.200000              0.291000      49.540000   \n",
      "\n",
      "         mean area  \n",
      "count   569.000000  \n",
      "mean    654.889104  \n",
      "std     351.914129  \n",
      "min     143.500000  \n",
      "25%     420.300000  \n",
      "50%     551.100000  \n",
      "75%     782.700000  \n",
      "max    2501.000000  \n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2",
   "id": "edf555fb6257c2ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:33.541635Z",
     "start_time": "2025-09-24T00:55:33.528033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Prepare the data\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# X_train Scaled\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "8e5a5db93a3102d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Why does scaling matter for some models but Naive Bayes?\n",
    "\n",
    "Scaling matters for models where outlier can negatively affect the predictions and scores such as KNN which uses distances. Scaling isn't necessary for Naive Bayes because it based on features distributions so the variation does not affect this model as much."
   ],
   "id": "7f80ce14d0df6553"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 3",
   "id": "cbf5e7b10a592f30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:33.602617Z",
     "start_time": "2025-09-24T00:55:33.590382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Baseline Models\n",
    "# predicts the majority class\n",
    "\n",
    "# Majority Class Baseline\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred = dummy.predict(X_test)\n",
    "\n",
    "# Find the accuracy\n",
    "accuracy_mb = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for majority class baseline: \", accuracy_mb)\n"
   ],
   "id": "e4041699275ba6f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for majority class baseline:  0.6257309941520468\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:33.673432Z",
     "start_time": "2025-09-24T00:55:33.653408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the baseline for Linear Regression\n",
    "# Threshold at 0.5\n",
    "\n",
    "# Initialize and Fit Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# Convert the continuous variables to categorical values so 1 or 0\n",
    "y_pred_classes = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# Find the Accuracy\n",
    "accuracy_lin = accuracy_score(y_test, y_pred_classes)\n",
    "print(\"Accuracy for Linear Regression baseline: \",accuracy_lin)"
   ],
   "id": "3715c42042aa6dfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Linear Regression baseline:  0.9298245614035088\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Limitations of using Linear Regression for Classification\n",
    "\n",
    "One limitation of using linear regression is because linear regression predicts continuous variables instead of an absolute value such as 0 or 1. Another limitation of linear regression is it's sensitivity to outliers as it can skew the predictions."
   ],
   "id": "1197527835f01bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 4",
   "id": "bad696debfdb3cd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:33.746066Z",
     "start_time": "2025-09-24T00:55:33.727909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4 Train and Evaluate Classifiers\n",
    "# Logistic Regression\n",
    "\n",
    "# Initialize and train the model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy for Logistic Regression\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy for Logistic Regression: \", accuracy_lr)"
   ],
   "id": "2099dc681efe962c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression:  0.9883040935672515\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:33.823295Z",
     "start_time": "2025-09-24T00:55:33.795173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN for k = 3\n",
    "# Initialize and fit  the model...\n",
    "knn_three = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_three.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_three= knn_three.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy for KNN\n",
    "accuracy_three = accuracy_score(y_test, y_pred_three)\n",
    "print(\"Accuracy for KNN classifier(3): \",accuracy_three)"
   ],
   "id": "4099dff83cd52af5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KNN classifier(3):  0.9532163742690059\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:33.902099Z",
     "start_time": "2025-09-24T00:55:33.877327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN for k = 5\n",
    "# Initialize and fit  the model...\n",
    "knn_five = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_five.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_five = knn_five.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy for KNN\n",
    "accuracy_five = accuracy_score(y_test, y_pred_five)\n",
    "print(\"Accuracy for KNN classifier(5): \",accuracy_five)"
   ],
   "id": "1b1ac2bf3bd3bc80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KNN classifier(5):  0.9590643274853801\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:33.982821Z",
     "start_time": "2025-09-24T00:55:33.950876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN for k = 7\n",
    "# Initialize and fit  the model...\n",
    "knn_seven = KNeighborsClassifier(n_neighbors=7)\n",
    "knn_seven.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_seven = knn_three.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy for KNN\n",
    "accuracy_seven = accuracy_score(y_test, y_pred_seven)\n",
    "print(\"Accuracy for KNN classifier(7): \",accuracy_seven)\n"
   ],
   "id": "41b18560aa58ec4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KNN classifier(7):  0.9532163742690059\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I think for k = 3, 5, 7 all gave the same accuracy score, might need to recheck. I redid it a few times, but I get the same scores, so I think it is correct",
   "id": "7536a19b6ab6b3a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:34.110141Z",
     "start_time": "2025-09-24T00:55:34.094348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gaussian Naive Bayes\n",
    "# Initialize and fit the model\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train) # not scaled\n",
    "\n",
    "# Predictions\n",
    "y_pred_naive = naive_bayes.predict(X_test)\n",
    "\n",
    "# Accuracy and Score\n",
    "accuracy_naive = accuracy_score(y_test, y_pred_naive)\n",
    "print(\"Accuracy for Naive Bayes: \",accuracy_naive)"
   ],
   "id": "13d4cc45c1bc305",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Naive Bayes:  0.9473684210526315\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:34.188806Z",
     "start_time": "2025-09-24T00:55:34.174196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Linear Discriminant Analysis\n",
    "# Initialize and fit the model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lda = lda.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_lda = accuracy_score(y_test, y_pred_lda)\n",
    "print(\"Accuracy for Linear Discriminant Analysis: \",accuracy_lda)"
   ],
   "id": "954345b7ec3ce52b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Linear Discriminant Analysis:  0.935672514619883\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T00:55:34.217175Z",
     "start_time": "2025-09-24T00:55:34.201220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quadratic Discriminant Analysis\n",
    "# Initialize and fit the model\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_qda = qda.predict(X_test_scaled)\n",
    "\n",
    "# Finding the accuracy and score\n",
    "accuracy_qda = accuracy_score(y_test, y_pred_qda)\n",
    "print(\"Accuracy for Quadratic Discriminant Analysis: \",accuracy_qda)"
   ],
   "id": "2acbef43a50ee612",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Quadratic Discriminant Analysis:  0.9473684210526315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georg\\miniconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Table comparing the models and their respective results",
   "id": "1c89ceb17e4f719b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T01:12:13.257342Z",
     "start_time": "2025-09-24T01:12:13.226356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary of models, accuracies, and notes\n",
    "models = {\n",
    "    \"Model\": [\n",
    "        'Majority Baseline',\n",
    "        'Linear Regression',\n",
    "        'LDA',\n",
    "        'QDA',\n",
    "        'Naive Bayes',\n",
    "        'Logistic Regression',\n",
    "        'KNN (k=3)',\n",
    "        'KNN (k=5)',\n",
    "        'KNN (k=7)'\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_mb,\n",
    "        accuracy_lin,\n",
    "        accuracy_lda,\n",
    "        accuracy_qda,\n",
    "        accuracy_naive,\n",
    "        accuracy_lr,\n",
    "        accuracy_three,\n",
    "        accuracy_five,\n",
    "        accuracy_seven\n",
    "    ],\n",
    "    \"Notes\": [\n",
    "        \"predict most frequent class\",\n",
    "        \"threshold 0.5, unscaled features\",\n",
    "        \"scaled features\",\n",
    "        \"scaled features\",\n",
    "        \"unscaled features\",\n",
    "        \"scaled features\",\n",
    "        \"scaled features\",\n",
    "        \"k = 5 best result\",\n",
    "        \"scaled features\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(models)\n",
    "\n",
    "# Display table\n",
    "display(df)\n"
   ],
   "id": "942e96828a899b9a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 Model  Accuracy                             Notes\n",
       "0    Majority Baseline  0.625731       predict most frequent class\n",
       "1    Linear Regression  0.929825  threshold 0.5, unscaled features\n",
       "2                  LDA  0.935673                   scaled features\n",
       "3                  QDA  0.947368                   scaled features\n",
       "4          Naive Bayes  0.947368                 unscaled features\n",
       "5  Logistic Regression  0.988304                   scaled features\n",
       "6            KNN (k=3)  0.953216                   scaled features\n",
       "7            KNN (k=5)  0.959064                 k = 5 best result\n",
       "8            KNN (k=7)  0.953216                   scaled features"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Majority Baseline</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>predict most frequent class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>threshold 0.5, unscaled features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.935673</td>\n",
       "      <td>scaled features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>scaled features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>unscaled features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.988304</td>\n",
       "      <td>scaled features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN (k=3)</td>\n",
       "      <td>0.953216</td>\n",
       "      <td>scaled features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN (k=5)</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>k = 5 best result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN (k=7)</td>\n",
       "      <td>0.953216</td>\n",
       "      <td>scaled features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 5\n",
    "\n",
    "5a: The model with the highest accuracy is Logistic Regression with a score of 0.982456\n",
    "\n",
    "5b: A smaller k for KNN might classify the data point as one class but a larger k might show different classes changing the value for that data point.\n",
    "\n",
    "5c: One real world reason for changing the ranking is the cost of these models. One model might be more effective but cost more. It may only better by a small margin so the increased cost would not be worth it.\n"
   ],
   "id": "7026d915bb6adfa2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
